# Install OpenCV with contrib to get SIFT
!pip install opencv-contrib-python --quiet

import cv2
import numpy as np
from google.colab import files
import os
from IPython.display import Image, display, HTML
import matplotlib.pyplot as plt
from base64 import b64encode

# Helper function to mark detected object with a dot
def mark_detected_object(query_img, target_img, kp1, kp2, good_matches):
    if len(good_matches) > 10:
        src_pts = np.float32([kp1[m.queryIdx].pt for m in good_matches]).reshape(-1,1,2)
        dst_pts = np.float32([kp2[m.trainIdx].pt for m in good_matches]).reshape(-1,1,2)

        M, mask = cv2.findHomography(src_pts, dst_pts, cv2.RANSAC, 5.0)
        if M is not None:
            h, w = query_img.shape
            # Calculate center point
            center = np.array([[w/2, h/2]], dtype='float32')
            center = np.array([center])
            # Transform center point to target image
            dst_center = cv2.perspectiveTransform(center, M)[0][0]
            # Draw a red dot at the center
            cv2.circle(target_img, (int(dst_center[0]), int(dst_center[1])), 5, (0, 0, 255), -1)
    return target_img

# Step 1: Upload query image (object/face to find)
print("üëâ Upload your query image (object/face you want to find):")
uploaded = files.upload()
query_image_path = next(iter(uploaded))
query_img = cv2.imread(query_image_path, cv2.IMREAD_GRAYSCALE)

# Initialize SIFT and matcher
sift = cv2.SIFT_create()
bf = cv2.BFMatcher(cv2.NORM_L2, crossCheck=True)
kp1, des1 = sift.detectAndCompute(query_img, None)

# Step 2: Ask user for image or video
target_type = input("üñº Is the target a single image or a video? Type 'image' or 'video': ").strip().lower()

# Step 3: Upload target file
print(f"üëâ Upload your target {target_type}:")
uploaded = files.upload()
target_path = next(iter(uploaded))

if target_type == 'image':
    target_img_color = cv2.imread(target_path)
    target_img_gray = cv2.cvtColor(target_img_color, cv2.COLOR_BGR2GRAY)
    kp2, des2 = sift.detectAndCompute(target_img_gray, None)
    matches = bf.match(des1, des2)
    matches = sorted(matches, key=lambda x: x.distance)
    good_matches = matches[:30]
    result = mark_detected_object(query_img, target_img_color.copy(), kp1, kp2, good_matches)

    # Convert BGR to RGB and display
    result_rgb = cv2.cvtColor(result, cv2.COLOR_BGR2RGB)
    plt.figure(figsize=(10, 6))
    plt.imshow(result_rgb)
    plt.title("Detected Object (marked with red dot)")
    plt.axis('off')
    plt.show()

elif target_type == 'video':
    cap = cv2.VideoCapture(target_path)
    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
    fps = cap.get(cv2.CAP_PROP_FPS)

    # Create output path with .mp4 extension
    output_path = 'output_detected_video.mp4'

    # Use appropriate codec for mp4 (H264)
    fourcc = cv2.VideoWriter_fourcc(*'mp4v')
    out = cv2.VideoWriter(output_path, fourcc, fps, (width, height))

    print("üé• Processing video...")

    while cap.isOpened():
        ret, frame = cap.read()
        if not ret:
            break

        frame_gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
        kp2, des2 = sift.detectAndCompute(frame_gray, None)

        if des2 is not None and len(des2) > 0:
            matches = bf.match(des1, des2)
            matches = sorted(matches, key=lambda x: x.distance)
            good_matches = matches[:30]
            frame = mark_detected_object(query_img, frame, kp1, kp2, good_matches)

        out.write(frame)

    cap.release()
    out.release()

    print("‚úÖ Done! Here's the video with detected object marked with red dots:")

    # Display the video
    mp4 = open(output_path, 'rb').read()
    data_url = "data:video/mp4;base64," + b64encode(mp4).decode()
    display(HTML(f"""
    <video width="640" controls>
        <source src="{data_url}" type="video/mp4">
    </video>
    """))

else:
    print("‚ùå Invalid option. Please type 'image' or 'video'.")
