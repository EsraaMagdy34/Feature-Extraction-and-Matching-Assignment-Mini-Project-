import cv2
import numpy as np
import os
import time
import tkinter as tk
from tkinter import filedialog

def select_file(title, filetypes):
    root = tk.Tk()
    root.withdraw()
    file_path = filedialog.askopenfilename(title=title, filetypes=filetypes)
    root.destroy()
    return file_path

def draw_matches_and_bbox(query_img, target_img, kp1, kp2, good_matches):
    # Draw all matches first
    img_matches = cv2.drawMatches(query_img, kp1, target_img, kp2, good_matches, None, 
                                 flags=cv2.DrawMatchesFlags_NOT_DRAW_SINGLE_POINTS)
    
    # Find homography and draw bounding box if enough matches are found
    if len(good_matches) > 10:
        src_pts = np.float32([kp1[m.queryIdx].pt for m in good_matches]).reshape(-1,1,2)
        dst_pts = np.float32([kp2[m.trainIdx].pt for m in good_matches]).reshape(-1,1,2)
        
        M, mask = cv2.findHomography(src_pts, dst_pts, cv2.RANSAC, 5.0)
        if M is not None:
            h, w = query_img.shape
            pts = np.float32([[0,0], [0,h-1], [w-1,h-1], [w-1,0]]).reshape(-1,1,2)
            dst = cv2.perspectiveTransform(pts, M)
            
            # Draw bounding box on target image
            target_img = cv2.polylines(target_img, [np.int32(dst)], True, (0,255,0), 3, cv2.LINE_AA)
            
            # Draw center point
            center = np.array([[[w/2, h/2]]], dtype='float32')
            dst_center = cv2.perspectiveTransform(center, M)[0][0]
            cv2.circle(target_img, (int(dst_center[0]), int(dst_center[1])), 10, (0,0,255), -1)
    
    return img_matches, target_img

def locate_object_in_image(query_img, target_img_path):
    # Read target image
    target_img = cv2.imread(target_img_path, cv2.IMREAD_GRAYSCALE)
    if target_img is None:
        print("‚ùå Failed to load target image")
        return None, None
    
    # Initialize SIFT detector
    sift = cv2.SIFT_create(contrastThreshold=0.04, edgeThreshold=10)
    
    # Find keypoints and descriptors
    kp1, des1 = sift.detectAndCompute(query_img, None)
    kp2, des2 = sift.detectAndCompute(target_img, None)
    
    # FLANN parameters and matcher
    FLANN_INDEX_KDTREE = 1
    index_params = dict(algorithm=FLANN_INDEX_KDTREE, trees=5)
    search_params = dict(checks=50)
    flann = cv2.FlannBasedMatcher(index_params, search_params)
    
    # Match descriptors
    matches = flann.knnMatch(des1, des2, k=2)
    
    # Lowe's ratio test to filter good matches
    good_matches = []
    for m, n in matches:
        if m.distance < 0.7 * n.distance:
            good_matches.append(m)
    
    # Draw matches and bounding box
    matches_img, result_img = draw_matches_and_bbox(query_img, target_img, kp1, kp2, good_matches)
    
    return matches_img, result_img

def process_video(query_img, kp1, des1, video_path):
    cap = cv2.VideoCapture(video_path)
    if not cap.isOpened():
        print("‚ùå Error: Could not open video file")
        return

    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
    fps = cap.get(cv2.CAP_PROP_FPS)
    
    output_path = os.path.join(os.path.dirname(video_path), "output_" + os.path.basename(video_path))
    fourcc = cv2.VideoWriter_fourcc(*'mp4v')
    out = cv2.VideoWriter(output_path, fourcc, fps, (width, height))
    
    sift = cv2.SIFT_create(contrastThreshold=0.04, edgeThreshold=10)
    flann = cv2.FlannBasedMatcher({'algorithm': 1, 'trees': 5}, {'checks': 50})
    
    print("üé¨ Processing video... (Press Q to stop)")
    start_time = time.time()
    
    while cap.isOpened():
        ret, frame = cap.read()
        if not ret:
            break
            
        frame_gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
        kp2, des2 = sift.detectAndCompute(frame_gray, None)
        
        if des2 is not None and len(des2) > 0:
            matches = flann.knnMatch(des1, des2, k=2)
            good_matches = [m[0] for m in matches if len(m) == 2 and m[0].distance < 0.7*m[1].distance]
            
            if len(good_matches) > 10:
                # Find homography and draw bounding box
                src_pts = np.float32([kp1[m.queryIdx].pt for m in good_matches]).reshape(-1,1,2)
                dst_pts = np.float32([kp2[m.trainIdx].pt for m in good_matches]).reshape(-1,1,2)
                
                M, mask = cv2.findHomography(src_pts, dst_pts, cv2.RANSAC, 5.0)
                if M is not None:
                    h, w = query_img.shape
                    pts = np.float32([[0,0], [0,h-1], [w-1,h-1], [w-1,0]]).reshape(-1,1,2)
                    dst = cv2.perspectiveTransform(pts, M)
                    frame = cv2.polylines(frame, [np.int32(dst)], True, (0,255,0), 3, cv2.LINE_AA)
        
        out.write(frame)
        cv2.imshow("Video Processing - Press Q to quit", frame)
        if cv2.waitKey(1) & 0xFF == ord('q'):
            break
    
    cap.release()
    out.release()
    cv2.destroyAllWindows()
    
    processing_time = time.time() - start_time
    print(f"‚úÖ Video processing completed in {processing_time:.2f} seconds")
    print(f"üíæ Output saved to: {output_path}")

def main():
    # Step 1: Select query image
    print("\n1Ô∏è‚É£ Select query image (object to find)")
    query_path = select_file("Select query image", [("Image files", "*.jpg *.jpeg *.png")])
    if not query_path:
        print("‚ùå No query image selected")
        return
    
    query_img = cv2.imread(query_path, cv2.IMREAD_GRAYSCALE)
    if query_img is None:
        print("‚ùå Failed to load query image")
        return
    
    # Initialize feature detector
    sift = cv2.SIFT_create(contrastThreshold=0.04, edgeThreshold=10)
    kp1, des1 = sift.detectAndCompute(query_img, None)
    
    # Step 2: Choose between image or video target
    choice = input("Choose target type (image/video): ").strip().lower()
    
    if choice == 'image':
        print("\n2Ô∏è‚É£ Select target image")
        target_path = select_file("Select target image", [("Image files", "*.jpg *.jpeg *.png")])
        if not target_path:
            print("‚ùå No target image selected")
            return
        
        # Process image
        matches_img, result_img = locate_object_in_image(query_img, target_path)
        
        if matches_img is not None and result_img is not None:
            # Display results
            cv2.imshow("Feature Matches", matches_img)
            cv2.imshow("Detection Result", result_img)
            cv2.waitKey(0)
            cv2.destroyAllWindows()
            
            # Save results
            output_dir = os.path.dirname(target_path)
            cv2.imwrite(os.path.join(output_dir, "matches.jpg"), matches_img)
            cv2.imwrite(os.path.join(output_dir, "result.jpg"), result_img)
            print(f"üíæ Results saved to: {output_dir}")
    
    elif choice == 'video':
        print("\n2Ô∏è‚É£ Select target video")
        video_path = select_file("Select target video", [("Video files", "*.mp4 *.avi *.mov")])
        if not video_path:
            print("‚ùå No video selected")
            return
        
        # Process video
        process_video(query_img, kp1, des1, video_path)
    
    else:
        print("‚ùå Invalid choice. Please enter 'image' or 'video'")

if __name__ == "__main__":
    main()
